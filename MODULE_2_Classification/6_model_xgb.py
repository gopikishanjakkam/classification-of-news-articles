# -*- coding: utf-8 -*-
"""xgboost capstone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mu00of5vTowKWiRe0HtCl-Nv7xqgJ4hh
"""

from google.colab import drive
drive.mount('/content/drive')

import itertools
import keras
import xgboost as xgb

import numpy as np
import pandas as pd
from keras import utils
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from keras.preprocessing import text
from sklearn.feature_extraction.text import TfidfVectorizer





data = pd.read_csv("/content/drive/My Drive/temp/cleaned_dataset_large_all_test.csv")

def get_features(data, num_words=7500, train_frac=0.8, mode='tfidf', one_hot=False, return_objects=False):

  data = data.sample(frac=1, random_state=77)
  data['label'].value_counts()

  train_size = int(len(data) * train_frac)
  print ("Train size: %d" % train_size)
  print ("Test size: %d" % (len(data) - train_size))

  train_situation = data['situation'][:train_size]
  train_label = data['label'][:train_size]
  test_situation = data['situation'][train_size:]
  test_label = data['label'][train_size:]

  max_words = num_words
  tokenizer = text.Tokenizer(num_words=max_words, char_level=False)
  tokenizer.fit_on_texts(train_situation) # only fit on train
  x_train = tokenizer.texts_to_matrix(train_situation, mode=mode) 
  x_test = tokenizer.texts_to_matrix(test_situation, mode=mode)



  # Use sklearn utility to convert label strings to numbered index
  encoder = LabelEncoder()
  encoder.fit(train_label)
  y_train = encoder.transform(train_label)
  y_test = encoder.transform(test_label)

  if(one_hot):
    num_classes = np.max(y_train) + 1
    y_train = utils.to_categorical(y_train, num_classes)
    y_test = utils.to_categorical(y_test, num_classes)


  # Inspect the dimenstions of our training and test data (this is helpful to debug)
  print('x_train shape:', x_train.shape)
  print('x_test shape:', x_test.shape)
  print('y_train shape:', y_train.shape)
  print('y_test shape:', y_test.shape)

  if return_objects:
    return x_train, x_test, y_train, y_test, tokenizer, encoder
  else:
    return x_train, x_test, y_train, y_test



x_train, x_test, y_train, y_test, tokenizer, encoder = get_features(data, num_words=7500, train_frac=0.8, mode='tfidf', one_hot=False, return_objects=True)

dtrain = xgb.DMatrix(data=x_train, label=y_train)
dtest = xgb.DMatrix(data=x_test)

params = {
    'max_depth': 5,
    'objective': 'multi:softmax',  # error evaluation for multiclass training
    'num_class': 8,
    'verbosity':3,
    'n_estimator':500,
    'tree_method':'gpu_hist'
}

bst = xgb.train(params, dtrain)

train_accuracy = accuracy_score(bst.predict(dtrain), y_train)
test_accuracy = accuracy_score(bst.predict(dtest), y_test)
print(train_accuracy)
print(test_accuracy)

def plot_confusion_matrix(cm, classes,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """

    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')


text_labels = encoder.classes_ 
y_pred = bst.predict(dtest)
cnf_matrix = confusion_matrix(y_test, y_pred)
#plt.figure(figsize=(10,8))
plot_confusion_matrix(cnf_matrix, classes=text_labels, title="Confusion matrix")
plt.show()

accuracy_score(y_test, y_pred)

#train on all data for final model
x_train, _, y_train, _, tokenizer, encoder = get_features(data, num_words=7500, train_frac=1, mode='tfidf', one_hot=False, return_objects=True)


del(bst)
dtrain = xgb.DMatrix(data=x_train, label=y_train)
bst = xgb.train(params, dtrain)

train_accuracy_fin = accuracy_score(bst.predict(dtrain), y_train)
print(train_accuracy_fin)

#save tokenizer, encoder, bst
import pickle

# saving
with open('tokenizer.pickle', 'wb') as handle:
    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('encoder.pickle', 'wb') as handle:
    pickle.dump(encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)

name = 'xgb_tr{}_te{}_tr{}.model'.format(round(train_accuracy,2), round(test_accuracy,2), round(train_accuracy_fin,2))

bst.save_model(name)

bst.dump_model('dump_{}.raw.txt'.format(name))# dump model with feature map

bst.dump_model?

